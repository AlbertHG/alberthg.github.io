---
layout:     post
title:      《机器学习要领》 偏差和方差（中文翻译版）
subtitle:   Machine Learning Yearning Chapter4 Bias and Variance(Chinese ver)
date:       2018-05-02
author:     ATuk
header-img: img/ML_yearning1.jpg
catalog: true
tags:
    - maching learning yearning
    - 机器学习
    - Andrew NG
    - 翻译
---

## 前言

> 人工智能、机器学习和深度学习正在越来越多的行业发挥着重要的作用。领域大牛吴恩达最近又有了小动作——正在完成一本开源的关于机器学习策略的手册，为各路道友提供构建机器学习项目的指导。根据NG的介绍，本书重点不是ML的算法，而是如何使ML算法发挥作用。琳琅满目的ML算法就像是工具箱里边的各种工具一样，这本书则是教会人们如何使用这些工具。笔者将对NG的这本 ~~葵花宝典~~ 武林秘籍进行翻译，本篇博客是“第四章：偏差和方差”，欢迎提出建议。   
👉[官网传送门](http://www.mlyearning.org/)<br>
👉[GitHub项目传送门](https://github.com/AlbertHG/Machine-Learning-Yearning-Chinese-ver)，欢迎Star

## 20. 偏差和方差：两大错误来源

假设你的训练、开发和测试集都服从同一分布，那么你应该总是试图去获取更多的训练数据，因为这能提高你的系统性能，对吗？

尽管，有大量可供获取的数据并没有坏处，但不幸的是，它并不是总能像你期望的那样给你带来帮助，有时候只顾着获取更多的数据只会是浪费时间。那么该如何决定什么时候添加数据什么时候不添加数据呢？

在机器学习中，有两个主要的错误来源：偏差(Bias)和方差(Variance)。了解这两个指标能够省时省力地帮助我们作出是否添加数据或者是其它能够提高系统性能的策略决定。

假设你希望构建一个只有5%误差的猫咪识别器。目前，你的训练集误差有15%，而开发集的误差有16%。这种情况下，往训练集塞更多的数据用处不大。此时的你应该关注其他变化。事实上，在你的训练集上增加更多的样本数据只会让你的算法在训练集上表现的越来越好而已。（我们会在后边的章节解释原因！）

如果当前你的算法在训练集上的误差是15%（准确率85%），而你的目标是降低误差到5%（准确率95%），因此首要的问题就是提高算法在训练集上的性能表现。算法在开发集和测试集的性能往往要低于训练集，也就是说，如果你的算法在你已有的数据上的准确率都只有85%的话，那么想要算法在未见过的示例中达到95%的准确率无异于是天方夜谭。

假设你的算法在开发集上的误差是16%（准确率84%），通常将16%的误差分为2部分：

- 首先，算法在训练集上的误差，在此例中是15%。我们非正式地把它看作是算法的偏差(Bias);
- 其次，算法在开发集上的表现和训练集上的表现的差值（开发集误差-训练集误差），在此例中，开发集和训练集的准确度差值为1%。我们非正式地把它看作是算法的方差(Variance)[^1]。
 
[^1]: 在统计学领域，有更正式的对于方差和偏差的定义。但大致上可以将偏差定义为当你有一个很大的训练集的时候算法在训练集上的误差；将方差定义为算法在测试集表现和训练集表现的差值。当你的误差指标是均方误差时，你可以写出指定这两个量的公式，并证明“总体误差=偏差+方差”。但为了简化叙述如何通过对方差和偏差的分析来解决机器学习问题，这里给出非正式定义的偏差和方差就足够了。

学习算法的一些优化措施能够解决误差的第一部分——偏差：提高算法在训练集上的表现。有一些优化措施能够解决误差的第二部分——方差：帮助算法顺利地从训练集迁移到开发/测试集上[^2]。要学会选择最能提升算法性能表现的优化方向，则深刻理解错误的这两个部分的优先级顺序是很有必要的。

[^2]:还有一些方法可以通过对系统架构进行重大改动来同时减少方差和偏差，但这往往操作难度很大。

培养关于偏差和方差的良好的直觉能够帮助你为算法选择有效的优化措施。

## 21. 举例说明偏差和方差

考虑我们的猫分类任务。 一个“理想”的分类器（比如人）在这项任务中可能会取得近乎完美的表现。

假设你的算法表现如下：

- 训练集误差 = 1%
- 开发集误差 = 11%

从上边的数据能看出什么问题吗？应用前一节的定义，我们估计该分类器的偏差为1%，同时方差为10%（11%-1%=10%）。因此，它存在高方差(High Variance)问题。分类器的训练集误差很小，但未能把在训练集上呈现的完美表现迁移到开发集中，这也被称为“过拟合”(Overfitting)。

现在，算法表现变成了下列所示：

- 训练集误差 = 15%
- 开发集误差 = 16%

我们估计该分类器的偏差达到了15%，方差是1%。这个分类器对训练集的拟合效果很差，误差居然有15%，但是它在开发集上的误差和训练集上相当（也有16%）。因此该分类器存在高方差(High Bias​​)问题，这也被称为“欠拟合”(Underfitting)。

再来看一种情况：

- 训练集误差 = 15%
- 开发集误差 = 30%

我们估计偏差为15%，方差也达到了15%。该分类器同时存在高偏差和高方差问题：训练集的表现效果很差，因此偏差很大，同时他在开发集的表现更差，因此方差也很大。这是由于分类器模型设计的有问题，属于最糟糕的情况，欠拟合/过拟合的技术很难应用到这类情况中来。

再来看最后一种情况：

- 训练集误差 = 0.5%
- 开发集误差 = 1%

这个分类器表现完美，同时拥有低方差和低偏差，祝贺你取得了这样的成绩。

## 22. 比较最优误差

在我们的猫咪识别器的例子中，理想的误差，即最优分类器的误差应该接近0%。一个人类几乎总是能认出照片里边的猫来，所以，我们也希望机器能达到这个水平。

有些问题难度更大，比如，假设你正在建立一个语言识别系统，并发现在音频片段中有14%都是背景噪声，或者是无法理解的内容，即使是人类来也无法识别出这部分信息。在这种情况下，意味着即使是“最佳的”语音识别系统也可能存在14%的误差。

假设在这个语音识别问题上，你的算法实现了：

- 训练集误差 = 15%
- 开发集误差 = 30%

从上边可以看出，算法在训练集上的性能表现已经接近了14%的最优误差，因此，就偏差和或者训练集性能而言，已经没有太大的改进空间了。但是由于该算法对于开发集的拟合并不好，因此对于方差而言存在着很大的改进空间。

这个例子类似上一节中的第三个例子（训练集误差15%，开发集误差30%）。如果最优误差是~0%，则15%的训练集误差就有很大改进空间，这表明执行减少偏差的改进措施是将会有效果。但是，如果最优误差为14%，则相同的训练集表现告诉我们在分类器的偏差方面能改进的空间真的很小。

对于这种最优误差远远大于0%的问题，这里关于算法误差更详细的分类。继续我们上边提到的语音识别的例子，30%的总开发集误差可细分为以下几类（类似的分类可以同时应用于对测试集误差的分析过程中）：

- 最优误差(Optimal Error Rate)：14%。假设我们定义：即使是世界上最优秀的语音系统也存在14%的误差。我们可以将这部分误差归类为学习算法偏差中“不可避免”的部分；
- 可避免偏差(Avoidable Bias)：1%。这被定义为是在训练误差和最优误差之间的差值（训练误差-最优误差）[^3]；
- 方差(Variance)：15%。这被定为是开发集误差和训练集误差之间的差值（开发集误差-训练集误差）。为了和我们之前的一些定义统一起来，偏差和可避免偏差有下列联系[^4]：
    - 偏差 = 最优误差 + 可避免偏差

[^3]:如果这个差值是负数，那么你的训练集的表现比最优分类器都还要好，意味着你的算法在训练集过拟合了，并且该算法已经“Over-Memorized”了训练集。你应该专注于减少方差，而不是继续减少偏差。

[^4]:选择些定义是为了更好地传达关于如何改进学习算法的思想。这些定义与统计学家对这些概念的定义并不一样。从技术上来说，本文所定义的“偏差”应该被称为“我们归因于偏差的误差”(Error we attribute to bias)，“可避免偏差”应该被称为“我们归因于学习算法的偏差超过最优误差的误差”(error we attribute to the learning algorithm's bias that is over the optimal error rate)。

“可避免偏差”反映了算法在训练集上的表现和“最优分类器”比还差多少。

方差的概念和前面的一样，没有变化。从理论上来说，我们总是可以通过大规模训练集的训练来将方差减少到零，只要使用足够大的训练集就可以完全避免方差，因此所有的方差都是“可避免的”。

再考虑一个例子，这里我们设定最优误差是14%:

- 训练集误差 = 15%
- 开发集误差 = 16%

再前一节的内容中，我们将有上述表现的分类器称为“高偏差”分类器。现在我们可以称该分类的可避免偏差只有1%，所以，这个算法已经很优秀了，几乎没有改进的空间了，因为它在开发集上的表现仅比最优分类器差了2%而已。

从这些例子中我们可以看出，知道最误差有助于指导我们进行后续的步骤。在统计学中，“最优误差”也被称为“贝叶斯误差”(​Bayes Error Rate)或者“贝叶斯率”

那我们怎么知道最优误差是多少呢？对于一些人类擅长的任务来说，例如识别图片或者音频片段转录等，你可以要求人类来去对训练集数据进行识别，也就是测量出人类对于这个训练集的准确率来。这将给出最优误差的估计（用人类水平误差替代最优误差）。但是如果你正在解决一个对于人类而已都很困难的任务（比如，预测要推荐什么电影或者是向用户展示何种广告），最有误差是很难用这种方法来估计的。

在“比较人类表现水平”（第33节-第35节）这一部分章节中，我将更加详细的讨论比较学习算法表现和人类水平(human-level)表现这一过程。

在最后几节内容中，你将学习到如何通过查看训练和开发集误差来估计可避免/不可避免的偏差和方差。下一节将讨论如何使用通过分析得到的洞察力来优先考虑使用减少偏差的技术还是使用减少方差的技术。根据项目当前的问题是“高（可避免）偏差”还是“高方差”，来应用完全不同的技术手段。请继续往下读！

---


🚧🚧🚧未完待续！🚧🚧🚧