---
layout:     post
title:      《机器学习要领》 不同分布下的训练和测试（中文翻译版）
subtitle:   Machine Learning Yearning Chapter7 Training and testing on different distributions(Chinese ver)
date:       2018-06-06
author:     Canary
header-img: img/ML_yearning1.jpg
catalog: true
tags:
    - maching learning yearning
    - 机器学习
    - Andrew NG
    - 翻译
---

## 前言

> 本篇博客是 Andrew NG 《Machine Learning Yearning》 的“第七章：不同分布下的训练和测试”翻译。本章内容将探讨当训练集的数据分布和开发/测试集的分布不一致的时候可能出现的情况。有时候不得不将与测试集不同分布的训练集用在构建模型上，那什么时候这种做法合适呢？如何确保你的算法表现总能在目标分布中表现良好呢？。开启本章内容，出发！   
👉[官网传送门](http://www.mlyearning.org/)<br>
👉[GitHub项目传送门](https://github.com/AlbertHG/Machine-Learning-Yearning-Chinese-ver)，欢迎Star

## 36. 当你不得不在不同分布中进行训练和测试

你将你的猫咪图片应用程序的用户上传的 1 万张图片，手动分类为 “猫” 和 “非猫” 两种。同时你也通过互联网下载了额外的 20 万张图片。这种情况下，你应该如何去定义训练/开发/测试集呢？

因为 1 万张来自于用户的猫咪图像密切反映了你的算法想要去拟合的数据概率分布，因此，你可以将这部分数据用于开发集和测试集。如果你正在训练对数据有大规模需求的算法(Data-Hungry Algorithm)，你可以将取自互联网的那 20 万张猫咪图片用于训练你的算法。这样的话，你的训练集和开发/测试集的数据就不服从同一分布了。这会对你的算法性能产生什么影响呢？

与其将数据单纯的划分为训练/开发/测试集，不如将 21 万张图片混合然后随机分配到训练/开发/测试集中。这种情况下，所有的数据均来自相同的分布了。但是我不推荐使用这种方法，因为 20.5万/21万 ≈ 97.6% 的开发/测试集数据会来自互联网图片，这比例并不能很好的反映出你数据的真实分布。切记，我们对选择开发/测试集的忠告：

- 选择能够映射出你在未来将要获得的数据，且表现出良好效果的开发集和测试集。

关于机器学习的大多数学术文献都认为训练集、开发集和测试集来自同一分布[^1]。在机器学习的早期，数据很稀缺，我们通常只能从某个概率分布中获取一个数据集，所以我们会随机的将这些数据分割为训练/开发/测试集，并假设所有的数据来自于同一分布，上述做法效果不错。

[^1]:有一些专门研究在不同分布下算法训练和测试的学术文献。例子包括：域适配(Domain Adaptation)、迁移学习(Transfer Learning)和多任务学习(Multitask Learning)等。但因为理论和实践之间仍存在巨大的差异，如果你的算法在数据集 A 上训练然后用一些不同类型的数据集 B 去测试，你的算法效果好坏可能会与你的运气密切相关（在这里，“运气”包括了研究人员为特定任务手工设计的特征，以及一些我们还不了解的因素），这使得对不同分布下算法训练和测试的学术研究难以系统的进行。

但在大数据时代，我们有能力获取到大量数据，例如猫的互联网图片。即使训练集的数据和开发/测试集的数据来源于不同分布，我们仍然希望用这些数据来用于算法学习，因为它可以为算法提供大量信息。

对于猫咪检测器的例子，与其将所有的用户上传的猫图分配给开发/测试集，不如将 5000 张（一半）分配给开发/测试集，然后将剩下的那 5000 张图片给训练集。这样，你的 205000 张训练集图片既包含了 5000 张来自用户上传的图片，也包含了那来自互联网的 20 万张图片，我们将在后续章节讨论为什么这种方法是有效的。

让我们来看第二个例子，假设你正在构建一个语音识别系统用来为语音控制的移动地图/导航应用程序转录街道地址。你有 2 万个用户口述街道名称的样本，同时你还有 50 万个用户讨论其他主题的音频样本。你可能将 10000 个街道相关的样本置入开发/测试集，并将剩下的 10000 个样本连同那 50 万个其他主题的样本用来进行算法的训练。

我们继续假设你的开发集数据和测试集数据来自同一分布。但是重要的是要明白不同的训练集和开发/测试集概率分布会带来一些额外的挑战。

## 37. 如何决定是否使用所有数据

假设你的猫咪检测器的训练集包含了 1 万张用户上传的图像。这些数据都是来自于和独立的开发/测试集相同的分布，同时代表的是你的算法想要表现良好的那种分布。你还有额外的 2 万张取自互联网的猫咪图片。你是否应该将 2万 + 1万 = 3万 这所有的图片作为你的训练集的数据？或者是放弃那 2 万张图片以防止你的学习算法出现偏差？

当使用早期的学习算法（比如手工设计计算机视觉特征，然后使用一个简单的线性分类器）时，合并这两种类型的数据导致性能更差的风险是存在的。因此，一些工程师会警告你不要把这来自网络的 2 万张图片包括进来。

但在当今这个强大、灵活的学习算法时代——比如大型神经网络——这种风险已经大大降低。如果你能负担得起用足够多的隐藏单元/层来构建一个神经网络，你就可以安全地将 2 万张图片添加到你的训练集中。

这种观察依赖于这样一个事实：存在 $x \rightarrow  y$ 的映射，对于来自不同分布的两种类型的数据都适用。换句话说，存在这样的一个系统，无论是输入来自互联网的图片还是输入用户上传的图片，它都能准确的预测出正确的标签来，即使不知道图像的来源。

添加额外的 2 万张图像会产生以下效果：

1. 它能为你的神经网络提供更多的例子说明猫是什么样子的。这很有帮助，因为互联网图片和用户上传的移动应用图片确实有一些相似之处。你的神经网络可以将从互联网图像中获得的一些知识应用到处理移动应用程序图像中来；
2. 它迫使神经网络分出一部分能力来学习特定于互联网图像的属性（例如分辨率较高，图像帧的不同分布等）。如果这些属性和移动应用程序中的图像差别很大的话，它将“消耗”掉一部分神经网络的性能。因此，从移动应用程序图像的分布中识别数据的能力就会降低——这是你真正关心的。理论上，这可能会影响算法的性能。

为了使用不同的术语来描述第二种效应，我们求助于虚拟人物夏洛克·福尔摩斯，他说你的大脑就像一个阁楼：它只有有限的空间。“每增加一点知识，你就会忘记一些你以前知道的东西。”因此，最重要的是，不要让无用的事实把有用的事实挤掉[^2]。

[^2]:阿瑟·柯南·道尔的《血字的研究》

幸运的是，如果你有足够的计算能力来构建一个足够大的神经网络——即足够大的阁楼——那么这不是一个严重的问题。你有足够的能力同时从互联网和移动应用图片中学习，而不需要担心两种类型的数据争夺你的阁楼容量。你的算法的“大脑”足够大，就不必担心阁楼空间用完。

但是如果你没有足够大的神经网络（或者其他高度灵活的学习算法），那么你应该更加注意你的训练集和你的开发/测试集的分布问题。

如果你认为你所拥有的数据对提升算法表现没有任何好处，那么，你应该出于计算原因而忽略这些数据。例如，假设你的开发/测试集主要包含了人物、地点、地标和动物的随机图片，可能你还有大量扫描的历史文档。

这些图片不包含任何类似于猫的元素。它们看起来完全不同于你的开发/测试集。没有必要将这些图片归类到反例中，因为这些样本对于算法来说并不能体现出前边提到的第一个效果——几乎没有哪一个神经网络能够从这些样本中学习出用于你的开发/测试集分布的知识。同时它们还会浪费神经网络的计算资源和表示能力。

## 38. 如何决定是否包含不一致的数据

假设你想学习预测纽约市的房价。考虑到房子的大小（输入特征 x）, 您需要预测价格（目标标签 y）。

纽约市的房价非常高。假设你有关于密歇根州底特律的房价的第二个数据集，那里的房价要低得多。你应该在你的训练集中包含这些数据吗?

如果给定相同的 x （房子大小一样），y 房子的价格则根据其是在纽约市还是在底特律（地点不同）而不同。如果你只关心预测纽约市的房价，那么把这两个数据集放在一起就会影响你的算法表现。在这种情况下，最好忽略不一致的底特律房价数据[^3]。

[^3]:有一种方法可以解决底特律数据与纽约市数据不一致的问题，即为每一个城市的训练样本添加额外的特征。给定输入 x ——现在指定了城市—— y 的目标值现在是明确的。然而，在实践中，我并没有经常看到这种做法。

这个纽约市和底特律的例子与移动应用程序和网络猫图片的例子有什么不同?

猫图像的例子是不同的，因为在给定输入图像 x 的情况下，即使不知道图像是互联网图像还是移动应用上传的图像，也可以可靠地预测标签 y 表明是否有猫。也就是说，有一个函数 $f(x)$ 可以可靠的从输入 x 映射到目标输出 y，即使不知道 x 的来源。因此，互联网图像识别任务与移动应用图像识别任务“一致”。这意味着除了计算成本之外，包含所有的样本几乎没有什么负面影响，或许还有一些潜在的显著优势。相比之下，纽约市和密歇根州底特律的数据并不一致，给定相同的 x（房子的大小），根据房子的位置，价格是非常不同的。

## 39. 数据加权

假设你有 20 万张来自互联网的图片和 5000 张来自移动应用用户的图片。这些数据集的大小之间的比率为 40:1。理论上，只要你建立一个巨大的神经网络，并对所有 205000 张图像进行足够长时间的训练，那么尝试让算法同时在网络图像和移动图像上都表现出色的做法并没有什么坏处。

但在实践中，与仅对 5000 幅图像进行训练相比，使用比移动应用程序图像多 40 倍的互联网图像来训练算法，可能意味着你需要花费 40 倍甚至更多的计算资源来对两者进行建模。

如果你没有庞大的计算资源，你可以给互联网图像一个低得多的权重作为妥协。

例如，假设你的优化目标是平方误差(Squared Error)（这对于分类任务来说不是一个好的选择，但它会简化我们的解释）。因此，我们的学习算法试图优化：

$$\underset{\theta }{min} \ \ \sum_{(x,y)\in MobileImg}\left ( h_{\theta } (x)-y\right )^2+\sum_{(x,y)\in InternetImg}\left ( h_{\theta } (x)-y\right )^2$$

上边公式第一项计算的是对 5000 张移动应用程序图像的平方误差求和，第二项计算的是对 20 万张移动互联网图像的平方误差求和，你可以对第二项设置超参数 $\beta$ 来优化公式：

$$\underset{\theta }{min} \ \ \sum_{(x,y)\in MobileImg}\left ( h_{\theta } (x)-y\right )^2+\beta  \sum_{(x,y)\in InternetImg}\left ( h_{\theta } (x)-y\right )^2$$

如果设定 $\beta = 1/40$ ，算法相当于给予了 5000 个移动图像和 20 万个互联网图像相同的重视程度。当然，你也可以通过结合验证集等方式，把参数 $β$ 设置为其他值。

通过降低附加的互联网图片的权重，你就不必构建一个庞大的神经网络来保障算法在这两种类型的任务上都有效运作。只有当您觉得附加的数据（互联网图片）与开发/测试集的分布差异较大，或者是附加的数据比来自与开发/测试集（移动应用程序图像）相同分布的数据大得多的时候，才需要这种类型的重新加权。

------

🚧🚧未完待续🚧🚧