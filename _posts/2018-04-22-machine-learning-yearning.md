---
layout:     post
title:      Translated "Machine Learning Yearning"
subtitle:   《Machine Learning Yearning》 翻译文稿
date:       2018-04-22
author:     ATuk
header-img: img/ML_yearning1.jpg
catalog: true
tags:
    - maching learning
    - 策略
    - Andrew NG
    - 翻译
---

## 前言

> 人工智能、机器学习和深度学习正在越来越多的行业发挥着重要的作用。领域大牛吴恩达最近又有了小动作——正在完成一本开源的关于机器学习策略的手册，为各路道友提供构建机器学习项目的指导。根据NG的介绍，本书重点不是ML的算法，而是如何使ML算法发挥作用。琳琅满目的ML算法就像是工具箱里边的各种工具一样，这本书则是教会人们如何使用这些工具。本篇博客将对NG的这本 ~~葵花宝典~~ 武林秘籍作简单的翻译，欢迎提出建议。   👉[官网传送门](http://www.mlyearning.org/)

## 为什么需要机器学习策略？

机器学习是很多重要应用的基础，包括网页搜索、垃圾邮件分类、语音识别、商品推荐等等。假设你和你的团队正在开发一项机器学习相关的应用，并且想实现项目的快速迭代。本书介绍的内容将会为你提供帮助。

例子：创立一个关于猫咪图片的创业公司

假设你正在建立一个新的公司，该公司将为爱猫人士提供丰富的猫咪图片。

![](https://raw.githubusercontent.com/AlbertHG/alberthg.github.io/master/makedown_img/20180422mlyearning/0.jpg)

其中的一个潮流的方法就是：使用神经网络搭建的计算机视觉系统来检测图片中的猫。

但，很不幸的是，系统的学习算法准确率并不尽如人意，因此，你在改进算法的过程中必须承担来自各个方面的巨大压力，那么，具体怎么办呢？

你的团队有很多改善算法点子，例如：

- 获取更多的数据：收集更多有关猫咪的图片；
- 收集更加多元化的训练集。比如，处在不同位置的猫咪的图片、有不同颜色的猫咪的图片、来自相机不同的参数拍摄出来的猫咪的图片……
- 通过跑更多轮数的梯度下降迭代，延长网络的训练时间；
- 尝试更大规模的神经网络，比如设置更多的层数、隐藏单元、参数等；
- 尝试较小规模的神经网络；
- 尝试在网络加入正则化（例如L2正则化）；
- 改变神经网络的结构（比如改变激活函数、隐藏单元的数量等等）
- ……

如果选择了正确的优化方向，你将实现一个领先业界的猫咪图库平台，然后带领你的公司走向巅峰。但是如果你的优化措施选择并不好，大概率你会浪费掉数个月的时间，结果依旧没有改善。你将如何继续呢？

本书将会告诉你怎么做！大多数的机器学习问题都会留下一些线索，这些线索则会告诉你什么是有用的尝试，什么是徒劳的。学会理解这些暴露出来的线索能够节省你数月甚至上年的开发时间。

## 如何利用本书帮助你的团队

读完本书之后，您将对如何为机器学习项目设定技术方向有一个深刻的理解。

但是你的队友们可能并不能理解您为什么要推荐一个这样一个特定的方向，比如，你建议要定义好一个单一的评价指标。关于你的建议，队友们并不信服，那么你将如何说服他们呢？

这也就是为什么本书的章节内容都这么简短的原因：你可以将需要的章节打印出来，让你的队友只需要阅读1-2页你想让他们理解的内容。

在优化问题上一个小小的改动就可能对你团队的产品产生巨大的影响。通过帮助团队做出高效的优化改动，来让你成为你团队里边的超级英雄吧。

## 预备知识和符号约定

如果你在MOOC平台或者Coursera上学习过一些机器学习相关的课程，或者是你有一些应用“监督学习”的经验，你将能够理解本章节的内容。

我假设你对“监督学习”非常熟悉：通过使用有标签的训练样例$(x,y)$，来学习一个从$x$映射到$y$的函数。“监督学习”算法包括了：线性回归、Logistics回归和神经网络。机器学习有很多形式，但大部分有实用价值的机器学习算法主要来自“监督学习”。

我会经常提到”神经网络“（也叫做“深度学习“），你只需要对他们有一个基本的了解。

如果你对上边提及的概念还很不是熟悉的话，建议观看Coursera上机器学习前三周的课程，网址是：[http://ml-class.org](http://ml-class.org)

## 规模化驱动下的机器学习发展

很多深度学习相关的想法已经存在了数十年，为什么它们现在突然又火了起来？

近期的两个最大的驱动因素是：

- 海量可供使用的数据。人们在数字设备上所花费的时间大大提高，借此产生的海量数据，能够用于训练机器学习算法。
- 大规模的计算。从前几年开始，我们才敢设计足够大的网络来充分利用我们拥有的海量数据。

具体来说，如果使用那些传统的学习算法，比如Logistics回归，即使我们拥有再多的数据，算法的“学习曲线”会变得平坦（高原效应）。这意味着，即使提供再多的数据，算法也会停止改进。

![](https://raw.githubusercontent.com/AlbertHG/alberthg.github.io/master/makedown_img/20180422mlyearning/1.jpg)

这看起来传统的算法并不知道怎么利用我们提供的海量数据。

对于同样的一个“监督学习”任务，如果你训练一个小型的神经网络，那么你可能会获得稍微好一点的性能表现。

![](https://raw.githubusercontent.com/AlbertHG/alberthg.github.io/master/makedown_img/20180422mlyearning/2.png)

在这里，所谓的小型神经网络指的是该网络只有少数的隐藏单元/层/参数。最后，逐渐增大你网络的规模，网络的性能表现也会同步提高[备注1]。

* [备注1]:该图显示了神经网络(NNs)在小数据集上也能做的很好，这个效果与神经网络(NNs)在大型数据集上表现出的良好效果并不一致。在小型数据集中，更多的取决于如何对特征进行手工设计，传统算法可能表现的更好也可能表现更差。比如，你有20个训练样本，那么是否使用Logistics回归或者神经网络可能无关紧要，对特征的手工设计比选择何种学习算法会对性能表现产生更大的影响。但是如果你有100万的训练样本，使用神经网络将会是一个明智的选择。

![](https://raw.githubusercontent.com/AlbertHG/alberthg.github.io/master/makedown_img/20180422mlyearning/3.png)

很多其他的细节，比如神经网络架构，也是非常重要的，这里边也有很多可以创新的地方。但，在今天来看，提高算法性能更有效的方法依然是：(i)规模更大的网络；(ii)更多的数据。

如何实现(i)和(ii)的过程非常复杂，本书将会详细讨论这些细节。我们将从对传统的学习算法和神经网络都有效的一般策略入手，为构建现代深度学习系统提出更加现代化的策略。

## 你的开发集和测试集

让我们回到一开始那个猫咪图片识别的例子来。你投入运营了一个手机App，用户可以上传很多不同类型的图片到你的App来。此时，你希望在App上实现一个自动识别猫咪图片的功能。

你的团队通过从不同的网站抓取到很多猫图（正例）和非猫图（反例）组成了一个很大的数据集，然后按照70%/30%的法则将数据集分为了训练集和测试集两部分。通过使用这些数据，团队实现了一个在训练集和测试集上均表现良好的猫咪检测器。

但是，当你将这个检测器部署到手机App上的时候，发现它的性能变得相当糟糕！

这……发生了什么？

你发现用户上传的图片数据和团队从网站上抓取下来作为训练集的图片数据存在差异：用户上传的图片普遍使用手机拍摄，这些图片的分辨率比较低，清晰度差甚至曝光不足，然而，你的训练集/测试集上的图片则是来自网页抓取的图片。因此，你的分类器算法并不能很好的泛化到App的实际场景中——识别来自手机拍摄的图片。

在大数据时代来临之前，使用70%/30%的比例随机分割训练集和测试集是传统机器学习的通用法则。这种做法是可行的，但是，当越来越多的应用部署在与训练集（来自网页抓取的图片）有着不同分布的使用场景（用户手机拍摄的图片）中的时候，这种分割做法就比较糟糕了。

我们通常定义：

- 训练集：对算法或者模型进行训练所使用的数据集；
- 开发集：用于调整参数，选择特征和做出其他算法相关决定的数据集，又称作“交叉验证集”；
- 测试集：只用来评估算法性能而不会对使用何种算法或者参数做出决策的数据集。

一旦定义好了开发集和测试集之后，你的团队将会尝试很多新的想法，例如，设置不同的学习算法参数来看一下哪种效果最佳。总之，开发集和测试集的使用可以让你的团队对算法调优进行快速迭代。

换句话说，*设置开发集和测试集的目的是指导你的团队对机器学习系统做出最正确的优化。*

因此，你应该遵从下列原则：

- 选择能够映射出你在未来将要获得的数据，且表现出良好效果的开发集和测试集。

也就是说，你的测试集不应该仅仅包含现阶段可用数据的30%，特别是当你期望得到的数据（用户的手机拍摄的图片）和你的训练集的数据（网站抓取的图片）来自不同分布的时候。

如果你还没有上线你的App，那么你可能还没有任何用户，因此无法获取符合未来数据分布的图片，但是您仍然可以尝试去模拟这种分布。比如，请求你的朋友们使用手机拍些猫咪的图片给你。一旦应用上线，就可以使用用户上传的数据去更新你的开发集和测试集了。

如果真的没有任何办法去获取那些符合未来数据分布的图片的话，也许你可以使用上边提到的网站抓取的图片来优化算法，但是应该清醒地意识到这种方式训练出来的系统的泛化性能肯定是不好的。

你需要有一定的判断力来决定投入多少预算去提高开发集和测试集的质量。切记不要假定你的训练集和测试集有着相同的分布，尝试挑选那些能够很好的体现出你最终想要的结果的数据作为测试样本，而不仅仅是挑那些和训练集有着相同分布的数据。


## 开发集和测试集应当服从同一分布

根据你的App的受众地区，将猫咪数据来源分为四个区域：(i)美国、(ii)中国，(iii)印度和(iv)其他。我们提出了一个服从这样分布的开发集和测试集：将美国和印度地区的数据归入开发集中，将来自中国和其他地区的数据归入测试集中。简单说就是，我们随机将两个地区的数据分配给开发集，另外两个分配给测试集。这种分法对吗？

错啦！！！

一旦定义好开发集和测试集，你的团队将会专注于提高开发集上的表现。所以，开发集应该要反映出你最想要改进的任务——在四个区域都表现良好，而不是其中的两个。

开发集和测试集服从不同分布导致的第二个问题是：你的团队可能会构建出来在开发集上表现良好的系统，但发现它在测试集中却表现很差，我曾在大量的挫折和错误的努力中得到过这种结果。现在要避免这种悲剧发生在你身上。

还是以例子来说明，假设你的团队构建的系统在开发集上表现良好但是在测试集却很糟糕。如果此时你的开发集和测试集服从同一个分布，那么你将非常清楚的知道哪里出了问题——数据过拟合了。一个有效的办法就是获取更多的开发集数据。

但是，如果开发集和测试集服从不同的分布，那么你的决策就不那么明朗了，以下几个方面都可能是出错的地方：

1. 你过拟合了开发集；
2. 测试集的数据比开发集数据要更加复杂，你的算法已经达到了预期的效果并且已经无法进一步改善了；
3. 测试集的数据并不比开发集数据复杂，只是因为服从不同分布，所以开发集上良好的性能表现并不能泛化到训练集中。在这种情况下，你在开发集上所做的努力就全部白费了。

开发机器学习应用已经足够困难，不匹配的开发集和测试集则引入了额外的不确定性——改进开发集的分布是否能提高测试集表现？这会使得更加难以确定哪些优化措施是有效的哪些是徒劳的，从而难以指定优化措施的优先级顺序。

如果你处理第三方的基准测试，它们的创建者可能指定了来自不同分布的开发集和训练集。与服从同一分布的开发集和训练集相比，对于基准测试的性能表现，运气将会比技巧产生更大的影响。当然，构建能够在一种分布中表现良好而且能泛化到其他分布的学习算法是很重要的研究方向。但是，如果你的目标是构建出能在特定的机器学习应用中取得进展的话，我建议你尝试选择服从同一分布的开发集和测试集，这会使您的团队更有效率。

🚧🚧（施工中）🚧🚧
